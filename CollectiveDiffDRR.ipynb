{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "gpuType": "V100",
      "authorship_tag": "ABX9TyMoIubGLZ06N2lFAtXWKFtq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BillWorstell/derenzo_phantom/blob/master/CollectiveDiffDRR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate 3D homogeneous projections from (Euclidean) volume images of a derenzo_phantom"
      ],
      "metadata": {
        "id": "FeH2Fi2aO9rT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install os and sys, mount drive\n",
        "import os\n",
        "import sys\n",
        "from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "!pip install icecream\n",
        "from icecream import ic\n",
        "\n",
        "import warnings\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3YqDeNk1h89",
        "outputId": "9908a25b-9f29-4088-ed74-2a3ced685513"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting icecream\n",
            "  Downloading icecream-2.1.3-py2.py3-none-any.whl (8.4 kB)\n",
            "Collecting colorama>=0.3.9 (from icecream)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from icecream) (2.16.1)\n",
            "Collecting executing>=0.3.1 (from icecream)\n",
            "  Downloading executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
            "Collecting asttokens>=2.0.1 (from icecream)\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from asttokens>=2.0.1->icecream) (1.16.0)\n",
            "Installing collected packages: executing, colorama, asttokens, icecream\n",
            "Successfully installed asttokens-2.4.1 colorama-0.4.6 executing-2.0.1 icecream-2.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "need_pytorch3d=False\n",
        "try:\n",
        "    import pytorch3d\n",
        "except ModuleNotFoundError:\n",
        "    need_pytorch3d=True\n",
        "if need_pytorch3d:\n",
        "    if torch.__version__.startswith(\"2.1.\") and sys.platform.startswith(\"linux\"):\n",
        "        # We try to install PyTorch3D via a released wheel.\n",
        "        pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "        version_str=\"\".join([\n",
        "            f\"py3{sys.version_info.minor}_cu\",\n",
        "            torch.version.cuda.replace(\".\",\"\"),\n",
        "            f\"_pyt{pyt_version_str}\"\n",
        "        ])\n",
        "        !pip install fvcore iopath\n",
        "        !pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
        "    else:\n",
        "        # We try to install PyTorch3D from source.\n",
        "        !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'"
      ],
      "metadata": {
        "id": "9UI1rz8sLrpS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e902c73-761e-4368-d5ce-fed11142d418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/pytorch3d.git@stable\n",
            "  Cloning https://github.com/facebookresearch/pytorch3d.git (to revision stable) to /tmp/pip-req-build-cvyky0a8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/pytorch3d.git /tmp/pip-req-build-cvyky0a8\n",
            "  Running command git checkout -q 2f11ddc5ee7d6bd56f2fb6744a16776fab6536f7\n",
            "  Resolved https://github.com/facebookresearch/pytorch3d.git to commit 2f11ddc5ee7d6bd56f2fb6744a16776fab6536f7\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fvcore (from pytorch3d==0.7.5)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath (from pytorch3d==0.7.5)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorch3d==0.7.5) (1.25.2)\n",
            "Collecting yacs>=0.1.6 (from fvcore->pytorch3d==0.7.5)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorch3d==0.7.5) (6.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorch3d==0.7.5) (4.66.2)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorch3d==0.7.5) (2.4.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorch3d==0.7.5) (9.4.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorch3d==0.7.5) (0.9.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from iopath->pytorch3d==0.7.5) (4.10.0)\n",
            "Collecting portalocker (from iopath->pytorch3d==0.7.5)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Building wheels for collected packages: pytorch3d, fvcore, iopath\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "AMbnmqqwYPU1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mount google drive and connect to output data path"
      ],
      "metadata": {
        "id": "0VlkVzV6TZaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "vHUS40s1TZaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load translations and rotations of phantom"
      ],
      "metadata": {
        "id": "hjMB0J5O-j4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RunTranslate=np.load('/content/gdrive/MyDrive/data/derenzo_phantom/RunTranslate.npy')\n",
        "ic(RunTranslate.shape)\n",
        "NRuns=RunTranslate.shape[0]\n",
        "ic(NRuns)\n",
        "\n",
        "RunRotate=np.load('/content/gdrive/MyDrive/data/derenzo_phantom/RunRotate.npy')\n",
        "ic(RunRotate.shape)\n",
        "NRuns=RunRotate.shape[0]\n",
        "ic(NRuns)"
      ],
      "metadata": {
        "id": "5op6C6HPYQG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load ground truth volumes orthogonal projections"
      ],
      "metadata": {
        "id": "4TaJEgaSKufY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NEvents=1\n",
        "\n",
        "for iEvent in range(0,NEvents):\n",
        "  ic(iEvent)\n",
        "  thisTruth=torch.load(f'/content/gdrive/MyDrive/data/derenzo_phantom/truth_{iEvent}.pt')\n",
        "  Truth=thisTruth.numpy()\n",
        "  Truth_Mod0_ZSum=torch.sum(thisTruth,dim=3).numpy()\n",
        "  Truth_Mod0_YSum=torch.sum(thisTruth,dim=2).numpy()\n",
        "  Truth_Mod0_XSum=torch.sum(thisTruth,dim=1).numpy()\n",
        "\n",
        "  TX=RunTranslate[iEvent,0]\n",
        "  TY=RunTranslate[iEvent,1]\n",
        "  TZ=RunTranslate[iEvent,2]\n",
        "  PsiDeg=(180./np.pi)*RunRotate[iEvent,0]\n",
        "  ThetaDeg=(180./np.pi)*RunRotate[iEvent,1]\n",
        "  PhiDeg=(180./np.pi)*RunRotate[iEvent,2]\n",
        "\n",
        "  plt.imshow(np.flipud(Truth_Mod0_ZSum.T),cmap='gray')\n",
        "  plt.title(f'Event{iEvent} Truth ZSum')\n",
        "  plt.xlabel(f'Event{iEvent} TX={TX:5.1f} TY={TY:5.1f} TZ={TZ:5.1f}')\n",
        "  plt.ylabel(f'Event{iEvent} Theta={ThetaDeg:.0f} Phi={PhiDeg:.0f}')\n",
        "  plt.show()\n",
        "\n",
        "  plt.imshow(np.flipud(Truth_Mod0_YSum.T),cmap='gray')\n",
        "  plt.title(f'Event{iEvent} Truth YSum')\n",
        "  plt.xlabel(f'Event{iEvent} TX={TX:5.1f} TY={TY:5.1f} TZ={TZ:5.1f}')\n",
        "  plt.ylabel(f'Event{iEvent} Theta={ThetaDeg:.0f} Phi={PhiDeg:.0f}')\n",
        "  plt.show()\n",
        "\n",
        "  plt.imshow(np.flipud(Truth_Mod0_XSum.T),cmap='gray')\n",
        "  plt.title(f'Event{iEvent} Truth XSum')\n",
        "  plt.xlabel(f'Event{iEvent} TX={TX:5.1f} TY={TY:5.1f} TZ={TZ:5.1f}')\n",
        "  plt.ylabel(f'Event{iEvent} Theta={ThetaDeg:.0f} Phi={PhiDeg:.0f}')\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "WeswMgPUuUJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get Multi-pinhole SPECT System Geometry"
      ],
      "metadata": {
        "id": "0XSm8shkIWRj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MmiGfTu_Nji"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/SPECTGeometry/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vc-1mcs_XjY"
      },
      "outputs": [],
      "source": [
        "!ls -ltr /content/drive/MyDrive/SPECTGeometry/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWhcNKnv_hqQ"
      },
      "source": [
        "Install openpyxl using pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Akz1LfPk_kiM"
      },
      "outputs": [],
      "source": [
        "pip install openpyxl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYKAO0aG_qEs"
      },
      "source": [
        "https://openpyxl.readthedocs.io/en/stable/tutorial.html#loading-from-a-file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYt5pfeM_rLE"
      },
      "outputs": [],
      "source": [
        "from openpyxl import load_workbook\n",
        "wb = load_workbook(filename = '/content/drive/MyDrive/SPECTGeometry/MDSL.excel80M10RFR.cut-plate.008.150roi.2.30pin.105ellipse.xlsx',data_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeozB2nC_1Kh"
      },
      "source": [
        "loop through worksheets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvCn0fFs_5k3"
      },
      "outputs": [],
      "source": [
        "for sheet in wb:\n",
        "...     print(sheet.title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9KfSlXw-MyE"
      },
      "source": [
        "Go to Coordinates Worksheet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1tstxQg-PZ5"
      },
      "outputs": [],
      "source": [
        "wb.active = 1\n",
        "print(wb.active.title)\n",
        "ws = wb.active"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "X,Y,Z Coordinates at the center of each pinhole"
      ],
      "metadata": {
        "id": "IPRM9M9qD7HQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ic(ws.cell(2,7).value)\n",
        "XP=np.zeros(80)\n",
        "YP=np.zeros(80)\n",
        "ZP=np.zeros(80)\n",
        "for i in range(3,83):\n",
        "  XP[i-3]=(ws.cell(i,2).value)\n",
        "  YP[i-3]=(ws.cell(i,3).value)\n",
        "  ZP[i-3]=(ws.cell(i,4).value)\n",
        "\n",
        "ic(XP[0])\n",
        "ic(YP[0])\n",
        "ic(ZP[0])"
      ],
      "metadata": {
        "id": "tFUkhdkLEGNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B701xj7J-RP9"
      },
      "source": [
        "Length of Collimator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kooFbujS-lpg"
      },
      "outputs": [],
      "source": [
        "ic(ws.cell(2,7).value)\n",
        "lcoll=np.zeros(80)\n",
        "for i in range(3,83):\n",
        "  lcoll[i-3]=(ws.cell(i,7).value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRyOy2f9-wAx"
      },
      "source": [
        "Choose vsdr = 5 * length of collimator, so by similar triangles\n",
        "\n",
        "(2*5*lcoll)=source to virtual detector, or 10X\n",
        "\n",
        "source to virtual detector is 10X size of actual detector\n",
        "\n",
        "Size of detector at end of collimator is ~50mm\n",
        "\n",
        "This implies dx * NX = 10 * 50mm ~ 500mm\n",
        "\n",
        "dx ~ 500/256 ~2mm\n",
        "\n",
        "    height=256,  # Height of the DRR (if width is not seperately provided, the generated image is square)\n",
        "    delx=1.0,  # Pixel spacing (in mm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTNlij9d-yfo"
      },
      "outputs": [],
      "source": [
        "vsdr=5.*lcoll"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkgfaYEz-zyh"
      },
      "source": [
        "alpha: Azimuthal angle (radians)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUeGRODX-4lX"
      },
      "outputs": [],
      "source": [
        "ic(ws.cell(2,22).value)\n",
        "alpha=np.zeros(80)\n",
        "for i in range(3,83):\n",
        "  alpha[i-3]=(ws.cell(i,22).value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKwyot0H_Ent"
      },
      "source": [
        "beta = altitude (radians)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aep2b-m_JPl"
      },
      "outputs": [],
      "source": [
        "ic(ws.cell(2,23).value)\n",
        "beta=np.zeros(80)\n",
        "for i in range(3,83):\n",
        "  beta[i-3]=(ws.cell(i,23).value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "We9ky2mzxXbh"
      },
      "source": [
        "#make meshgrid from volume and spacing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ue0amxUaxxWq"
      },
      "outputs": [],
      "source": [
        "#volume, spacing = load_example_ct()\n",
        "volume=np.zeros([256,256,256])\n",
        "spacing=[1.0, 1.0, 1.0]\n",
        "bx, by, bz = torch.tensor(volume.shape) * torch.tensor(spacing) / 2\n",
        "ic(bx, by, bz)\n",
        "ic(volume.shape)\n",
        "ic(spacing)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get lab frame coordinates for voxels in volume"
      ],
      "metadata": {
        "id": "SlEGfyXqGrsy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyeyxrccyFsB"
      },
      "outputs": [],
      "source": [
        "xlinspace=np.linspace(-128*spacing[0], 128*spacing[0], 256)\n",
        "ylinspace=np.linspace(-128*spacing[1], 128*spacing[1], 256)\n",
        "zlinspace=np.linspace(-128*spacing[2], 128*spacing[2], 256)\n",
        "xgrid,ygrid,zgrid = np.meshgrid(xlinspace, ylinspace,zlinspace)\n",
        "xgrid=xgrid.flatten()\n",
        "ygrid=ygrid.flatten()\n",
        "zgrid=zgrid.flatten()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define camera[0] using PyTorch3D methods"
      ],
      "metadata": {
        "id": "zt-mOQF50gZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import methods from pytorch3d"
      ],
      "metadata": {
        "id": "ISIG6CRL4HwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# io utils\n",
        "from pytorch3d.io import load_obj\n",
        "\n",
        "# datastructures\n",
        "from pytorch3d.structures import Meshes\n",
        "\n",
        "# 3D transformations functions\n",
        "from pytorch3d.transforms import Rotate, Translate\n",
        "\n",
        "# rendering components\n",
        "from pytorch3d.renderer import (\n",
        "    PerspectiveCameras, OrthographicCameras, FoVOrthographicCameras,\n",
        "    FoVPerspectiveCameras, look_at_view_transform, look_at_rotation,\n",
        "    RasterizationSettings, MeshRenderer, MeshRasterizer, BlendParams,\n",
        "    SoftSilhouetteShader, HardPhongShader, PointLights, TexturesVertex,\n",
        ")"
      ],
      "metadata": {
        "id": "7Zv62Gyd4IJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Map from k-depth extended projection image 3D tensor to 3d volume"
      ],
      "metadata": {
        "id": "9HemRbUaZjqb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mount google drive and connect to output data path"
      ],
      "metadata": {
        "id": "ZUx3PEUd-aOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "o5SmCMff-aO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look around data area"
      ],
      "metadata": {
        "id": "-fZr7rHaTZaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -ltr /content/gdrive/MyDrive/data/derenzo_phantom/truth_0.pt\n",
        "!ls -ltr /content/gdrive/MyDrive/data/derenzo_phantom/Projections_0.pt\n",
        "!ls -ltr /content/gdrive/MyDrive/data/derenzo_phantom/ProjRadon96_0.pt\n",
        "!ls -ltr /content/gdrive/MyDrive/data/derenzo_phantom/ProjRadon256_0.pt\n",
        "!ls -ltr /content/gdrive/MyDrive/data/derenzo_phantom/RunTranslate.npy\n",
        "!ls -ltr /content/gdrive/MyDrive/data/derenzo_phantom/RunRotate.npy"
      ],
      "metadata": {
        "id": "dFFwYpr1TZaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up projective geometry for comparison with diffDRR as called earlier by iDerenzoRandomTomograph.ipynb"
      ],
      "metadata": {
        "id": "AMT2PZNKYert"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yfCIyrZZEGI"
      },
      "source": [
        "Length of Collimator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRn4ohHWZEGJ"
      },
      "outputs": [],
      "source": [
        "ic(ws.cell(2,7).value)\n",
        "lcoll=np.zeros(80)\n",
        "for i in range(3,83):\n",
        "  lcoll[i-3]=(ws.cell(i,7).value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyMM03FQGJe2"
      },
      "source": [
        "##Get DiffDRR version from github"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OahSAZfbG-_v"
      },
      "source": [
        "Use the version of DiffDRR posted on github"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8U5Xl_6HdQpo"
      },
      "source": [
        "Git clone from github publib open source code to colab working directory\n",
        "\n",
        "See https://stackoverflow.com/questions/50850216/google-colab-install-from-github-glrm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAQelSm2GKNq"
      },
      "outputs": [],
      "source": [
        "#!pip install 'git+https://github.com/BillWorstell/DiffDRR.git'\n",
        "!pip install 'git+https://github.com/eigenvivek/DiffDRR.git'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import diffDRR modules"
      ],
      "metadata": {
        "id": "9e81NP0sEkuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from diffdrr.data import load_example_ct\n",
        "from diffdrr.drr import DRR\n",
        "from diffdrr.visualization import plot_drr\n",
        "from diffdrr.pose import RigidTransform\n",
        "from diffdrr.pose import convert"
      ],
      "metadata": {
        "id": "MtACYCNWv4cJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "import euler_angles_to_matrix"
      ],
      "metadata": {
        "id": "dP-xLa05vpf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#volume, spacing = load_example_ct()\n",
        "#volume=np.zeros([256,256,256])\n",
        "spacing=[1.0, 1.0, 1.0]\n",
        "ic(spacing)\n",
        "\n",
        "for iRun in range(0,NRuns):\n",
        "  thisTruth=torch.load(f'/content/gdrive/MyDrive/data/derenzo_phantom/truth_{iEvent}.pt')\n",
        "  volume = torch.squeeze(thisTruth)\n",
        "  ic(volume.shape)\n",
        "  #\n",
        "  for imod in range(0,2):\n",
        "    ############################\n",
        "    # Generate DRRs\n",
        "    ############################\n",
        "    #\n",
        "    #| cuda\n",
        "    # Read in the volume and get the isocenter\n",
        "    bx, by, bz = torch.tensor(volume.shape) * torch.tensor(spacing) / 2\n",
        "    # Initialize the DRR module for generating synthetic X-rays\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    #Collect Projections over all modules\n",
        "    #Projections=torch.zeros([1,96,256,256])\n",
        "\n",
        "    ic(iRun)\n",
        "    drr = DRR(\n",
        "      volume,  # The CT volume as a numpy array\n",
        "      spacing,  # Voxel dimensions of the CT\n",
        "      sdr=float(vsdr[imod]),  # Source-to-detector radius (half of the source-to-detector distance)\n",
        "      height=256,  # Height of the DRR (if width is not seperately provided, the generated image is square)\n",
        "      delx=2.0,  # Pixel spacing (in mm)\n",
        "    ).to(device)\n",
        "\n",
        "    # Set the camera pose with rotations (yaw, pitch, roll) and translations (x, y, z)\n",
        "    rotations = torch.tensor([[float(alpha[imod]), float(beta[imod]), torch.pi / 2]], device=device)\n",
        "    translations = torch.tensor([[bx, by, bz]], device=device)\n",
        "    img = drr(rotations, translations, parameterization=\"euler_angles\", convention=\"ZYX\")\n",
        "\n",
        "    pose = convert(rotations, translations, parameterization=\"euler_angles\", convention=\"ZYX\")\n",
        "    source, rays = drr.detector(pose)\n",
        "    ic(source.shape)\n",
        "    ic(source)\n",
        "    ic(rays.shape)\n",
        "\n",
        "    source_ = source.detach().cpu()\n",
        "    rays_ = rays.permute(2, 0, 1).detach().cpu()\n",
        "\n",
        "    if(imod==0):\n",
        "      Projection_mod0=torch.squeeze(img).cpu().numpy()\n",
        "    if(imod==1):\n",
        "      Projection_mod1=torch.squeeze(img).cpu().numpy()\n"
      ],
      "metadata": {
        "id": "HaGxZDSF8DAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display Event0 Mod0 Projection"
      ],
      "metadata": {
        "id": "1GTAhwtZw2vR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ic(Projection_mod0.shape)\n",
        "plt.imshow(np.flipud(Projection_mod0.T),cmap='gray')\n",
        "\n",
        "#  ThisAspect=24/256\n",
        "#  plt.imshow(np.flipud(eventProjections_2DZSumRow2.T),cmap='gray',aspect=ThisAspect)\n",
        "plt.title(f'Event{iEvent} Projection_mod0')\n",
        "plt.xlabel(f'Event{iEvent} TX={TX:5.1f} TY={TY:5.1f} TZ={TZ:5.1f}')\n",
        "plt.ylabel(f'Event{iEvent} Theta={ThetaDeg:.0f} Phi={PhiDeg:.0f}')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LkrZfaKBxA-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://vivekg.dev/DiffDRR/tutorials/optimizers.html"
      ],
      "metadata": {
        "id": "4J339aY-gSVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from diffdrr.utils import make_intrinsic_matrix\n",
        "from diffdrr.utils import get_focal_length\n",
        "from diffdrr.utils import get_principal_point\n",
        "\n",
        "for imod in range(0,1):\n",
        "    drr = DRR(\n",
        "    volume,  # The CT volume as a numpy array\n",
        "    spacing,  # Voxel dimensions of the CT\n",
        "    sdr=float(vsdr[imod]),  # Source-to-detector radius (half of the source-to-detector distance)\n",
        "    height=256,  # Height of the DRR (if width is not seperately provided, the generated image is square)\n",
        "    delx=2.0,  # Pixel spacing (in mm)\n",
        "    ).to(device)\n",
        "\n",
        "    thisIntrinsicMatrix=make_intrinsic_matrix(sdr=float(vsdr[imod]), delx=2.0, dely=2.0, height=256, width=256, x0=0.0, y0=0.0).to(device)\n",
        "    ic(thisIntrinsicMatrix)\n",
        "\n",
        "    thisFocalLength=get_focal_length (thisIntrinsicMatrix, delx=2.0, dely=2.0)\n",
        "    ic(thisFocalLength)\n",
        "\n",
        "    thisPrincipalPoint=get_principal_point (thisIntrinsicMatrix,  height=256, width=256, delx=2.0, dely=2.0)\n",
        "    ic(thisPrincipalPoint)\n",
        "\n",
        "  # Set the camera pose with rotations (yaw, pitch, roll) and translations (x, y, z)\n",
        "    rotations = torch.tensor([[float(alpha[imod]), float(beta[imod]), torch.pi / 2]], device=device)\n",
        "    translations = torch.tensor([[bx, by, bz]], device=device)\n",
        "    img = drr(rotations, translations, parameterization=\"euler_angles\", convention=\"ZYX\")\n",
        "\n",
        "    if(imod==0):\n",
        "      Projection_mod0=torch.squeeze(img).cpu().numpy()\n",
        "    if(imod==1):\n",
        "      Projection_mod1=torch.squeeze(img).cpu().numpy()\n",
        "    plot_drr(img)\n",
        "\n",
        "    plt.title(f'Event{iEvent} plot_drr_mod0')\n",
        "    plt.xlabel(f'Event{iEvent} TX={TX:5.1f} TY={TY:5.1f} TZ={TZ:5.1f}')\n",
        "    plt.ylabel(f'Event{iEvent} Theta={ThetaDeg:.0f} Phi={PhiDeg:.0f}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "COf8kAEbgTQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From https://tutorial.pyvista.org/getting-started.html"
      ],
      "metadata": {
        "id": "Tr9IkSg7_ZZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -qq xvfb libgl1-mesa-glx\n",
        "!pip install pyvista -qq\n",
        "!sudo apt install libgl1-mesa-glx xvfb"
      ],
      "metadata": {
        "id": "-WpoOSp3_VYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyvista\n",
        "\n",
        "pyvista.set_jupyter_backend('static')\n",
        "pyvista.global_theme.notebook = True\n",
        "pyvista.start_xvfb()"
      ],
      "metadata": {
        "id": "qi7vPWGY_jnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From https://vivekg.dev/DiffDRR/tutorials/visualization.html\n"
      ],
      "metadata": {
        "id": "IL2bqf8XkKJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from diffdrr.visualization import drr_to_mesh, img_to_mesh\n",
        "\n",
        "for imod in range(0,1):\n",
        "  drr = DRR(\n",
        "  volume,  # The CT volume as a numpy array\n",
        "  spacing,  # Voxel dimensions of the CT\n",
        "  sdr=float(vsdr[imod]),  # Source-to-detector radius (half of the source-to-detector distance)\n",
        "  height=256,  # Height of the DRR (if width is not seperately provided, the generated image is square)\n",
        "  delx=2.0,  # Pixel spacing (in mm)\n",
        "  ).to(device)\n",
        "\n",
        "  # Set the camera pose with rotations (yaw, pitch, roll) and translations (x, y, z)\n",
        "  rotations = torch.tensor([[float(alpha[imod]), float(beta[imod]), torch.pi / 2]], device=device)\n",
        "  ic(rotations)\n",
        "  translations = torch.tensor([[bx, by, bz]], device=device)\n",
        "  img = drr(rotations, translations, parameterization=\"euler_angles\", convention=\"ZYX\")\n",
        "\n",
        "  # Make a mesh from the CT volume\n",
        "  ct = drr_to_mesh(drr, \"surface_nets\", threshold=0.00001, verbose=False)\n",
        "  #ct = drr_to_mesh(drr, \"marching_cubes\", threshold=0.0001, verbose=False)\n",
        "  # Make the plot\n",
        "  plotter = pyvista.Plotter()\n",
        "  plotter.add_mesh(ct)\n",
        "  # Make a mesh from the camera and detector plane\n",
        "  pose = convert(rotations, translations, parameterization=\"euler_angles\", convention=\"ZYX\")\n",
        "  camera, detector, texture, principal_ray = img_to_mesh(drr, pose)\n",
        "  ic(principal_ray)\n",
        "\n",
        "  # Make the plot\n",
        "  plotter = pyvista.Plotter()\n",
        "  plotter.add_mesh(ct)\n",
        "  plotter.add_mesh(camera, show_edges=True, line_width=1.5)\n",
        "  plotter.add_mesh(principal_ray, color=\"lime\", line_width=3)\n",
        "  plotter.add_mesh(detector, texture=texture)\n",
        "\n",
        "  # Render the plot\n",
        "  plotter.add_axes()\n",
        "  plotter.add_bounding_box()\n",
        "  plotter.show()\n",
        "  #plotter.show(jupyter_backend=\"server\")  # If running Jupyter remotely\n"
      ],
      "metadata": {
        "id": "xsuV-AzlkdWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Event0 mod11"
      ],
      "metadata": {
        "id": "uiOtpo7lkXq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  for imod in range(5,6):\n",
        "\n",
        "    drr = DRR(\n",
        "    volume,  # The CT volume as a numpy array\n",
        "    spacing,  # Voxel dimensions of the CT\n",
        "    sdr=float(vsdr[imod]),  # Source-to-detector radius (half of the source-to-detector distance)\n",
        "    height=256,  # Height of the DRR (if width is not seperately provided, the generated image is square)\n",
        "    delx=2.0,  # Pixel spacing (in mm)\n",
        "    ).to(device)\n",
        "\n",
        "    # Set the camera pose with rotations (yaw, pitch, roll) and translations (x, y, z)\n",
        "    rotations = torch.tensor([[float(alpha[imod]), float(beta[imod]), torch.pi / 2]], device=device)\n",
        "    translations = torch.tensor([[bx, by, bz]], device=device)\n",
        "    img = drr(rotations, translations, parameterization=\"euler_angles\", convention=\"ZYX\")\n",
        "\n",
        "    if(imod==0):\n",
        "      Projection_mod0=torch.squeeze(img).numpy()\n",
        "    if(imod==1):\n",
        "      Projection_mod1=torch.squeeze(img).numpy()\n",
        "    plot_drr(img)\n",
        "\n",
        "    plt.title(f'Event{iEvent} plot_drr_mod5')\n",
        "    plt.xlabel(f'Event{iEvent} TX={TX:5.1f} TY={TY:5.1f} TZ={TZ:5.1f}')\n",
        "    plt.ylabel(f'Event{iEvent} Theta={ThetaDeg:.0f} Phi={PhiDeg:.0f}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "jeRTYSGmiEVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for imod in range(5,6):\n",
        "  drr = DRR(\n",
        "  volume,  # The CT volume as a numpy array\n",
        "  spacing,  # Voxel dimensions of the CT\n",
        "  sdr=float(vsdr[imod]),  # Source-to-detector radius (half of the source-to-detector distance)\n",
        "  height=256,  # Height of the DRR (if width is not seperately provided, the generated image is square)\n",
        "  delx=2.0,  # Pixel spacing (in mm)\n",
        "  ).to(device)\n",
        "\n",
        "  # Set the camera pose with rotations (yaw, pitch, roll) and translations (x, y, z)\n",
        "  rotations = torch.tensor([[float(alpha[imod]), float(beta[imod]), torch.pi / 2]], device=device)\n",
        "  ic(rotations)\n",
        "  translations = torch.tensor([[bx, by, bz]], device=device)\n",
        "  img = drr(rotations, translations, parameterization=\"euler_angles\", convention=\"ZYX\")\n",
        "\n",
        "  # Make a mesh from the CT volume\n",
        "  ct = drr_to_mesh(drr, \"surface_nets\", threshold=0.00001, verbose=False)\n",
        "\n",
        "  # Make the plot\n",
        "  plotter = pyvista.Plotter()\n",
        "  plotter.add_mesh(ct)\n",
        "    # Make a mesh from the camera and detector plane\n",
        "  pose = convert(rotations, translations, parameterization=\"euler_angles\", convention=\"ZYX\")\n",
        "  camera, detector, texture, principal_ray = img_to_mesh(drr, pose)\n",
        "  ic(principal_ray)\n",
        "\n",
        "  # Make the plot\n",
        "  plotter = pyvista.Plotter()\n",
        "  plotter.add_mesh(ct)\n",
        "  plotter.add_mesh(camera, show_edges=True, line_width=1.5)\n",
        "  plotter.add_mesh(principal_ray, color=\"lime\", line_width=3)\n",
        "  plotter.add_mesh(detector, texture=texture)\n",
        "\n",
        "  # Render the plot\n",
        "  plotter.add_axes()\n",
        "  plotter.add_bounding_box()\n",
        "  plotter.show()"
      ],
      "metadata": {
        "id": "IOfH2cExCEP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZOBzOd3Qa0I2"
      }
    }
  ]
}